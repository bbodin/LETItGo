{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "What kind of question would we like to answer ... \n",
    "\n",
    " Overall, these experiments will help use to estimate by how much the use of the upper bound in computing the age latency can be beneficial. \n",
    " \n",
    " there are two case to consider, optimum and eapproximate. \n",
    " First the optimum case, by how much using the lower can accelerate the search (in term of iterations, or more generally in term of execution time). \n",
    " Secondly by introducing the lower bound to our mechanism, we also enable approximate solution with garanties in delta. By considering several situations of acceptable errors (such as 1%, 5%, 10%, 15%), by how much the computation of age latency can be improved. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn cairosvg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sample data files and loading them... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXEC_PATH=\"../cmake-build-release/src/\"\n",
    "BENCHMARK = EXEC_PATH + \"/benchmarkAgelatency\"\n",
    "ANALYSE = EXEC_PATH + \"/lig-analyse\"\n",
    "ALL_KIND=[\"automotive\", \"generic\", \"harmonic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data\n",
    "!if [ ! -e data/automotive.csv ]; then echo Not found; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script env BENCHMARK=\"$BENCHMARK\" bash\n",
    "\n",
    "for kind in automotive harmonic generic; do \n",
    "    if [ ! -e data/$kind.csv ]; then \n",
    "        $BENCHMARK  -kind $kind -begin_n 10 -end_n 30  -step_n 10 -sample_count 5 -iter_count 1 -detailed -logfile data/\"$kind\".csv; \n",
    "    fi\n",
    "\n",
    "    if [ ! -e data/\"$kind\"diti.csv ]; then  \n",
    "        $BENCHMARK  -kind $kind -begin_n 10 -end_n 30  -step_n 10 -sample_count 5 -iter_count 1 -DiEqualTi -detailed -logfile data/\"$kind\"diti.csv; \n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script env BENCHMARK=\"$BENCHMARK\" bash\n",
    "\n",
    "if [ ! -e data/containsAnomalies.csv ]; then $BENCHMARK -begin_n 4 -end_n 5 -kind generic -step_n 1 -detailed -iter_count 1 -sample_count 10000 -logfile data/containsAnomalies.csv; fi\n",
    "if [ ! -e data/containsAnomalies_diti.csv ]; then $BENCHMARK -begin_n 4 -end_n 5 -kind generic -step_n 1 -detailed -iter_count 1 -sample_count 10000 -logfile data/containsAnomalies_diti.csv -DiEqualTi; fi\n",
    "if [ ! -e data/seek3.csv ]; then $BENCHMARK -begin_n 3 -end_n 5 -kind generic -step_n 1 -detailed -iter_count 1 -sample_count 10000 -logfile data/seek3.csv; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools to load the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def openLog(filename, with_gain=[]):\n",
    "    toIntList = lambda x: [int(y) for y in x.strip(\"[]\").split(\",\")] if x != \"[]\" else []\n",
    "    toFloatList = lambda x: [float(y) for y in x.strip(\"[]\").split(\",\")] if x != \"[]\" else []\n",
    "    df = pd.read_csv(filename, sep=\";\",\n",
    "                     converters={\n",
    "                         \"ExpansionVertex\": toIntList,\n",
    "                         \"ExpansionEdges\": toIntList,\n",
    "                         \"LowerBounds\": toIntList,\n",
    "                         \"UpperBounds\": toIntList,\n",
    "                         \"gen_time\": toFloatList,\n",
    "                         \"lbp_time\": toFloatList,\n",
    "                         \"ubp_time\": toFloatList,\n",
    "                     }\n",
    "                    )\n",
    "    \n",
    "    # Check data is as expected\n",
    "    assert(\"seed\" in df.columns)\n",
    "\n",
    "    # Remove zero-task cases, annoying and useless.\n",
    "    df = df[df[\"n\"] > 0]\n",
    "    \n",
    "    # Add extra data about filename\n",
    "    df[\"filename\"] = filename\n",
    "    \n",
    "    # Pick up the edge dentisty \n",
    "    df[\"edge_density\"] = df[\"m\"] / (df[\"n\"]  * (df[\"n\"] - 1))\n",
    "    df[\"edge_density\"] = df[\"edge_density\"].apply(lambda x : \"1.High\" if x > 0.3 else \"2.Medium\" if x > 0.2 else \"3.Low\")\n",
    "    \n",
    "    \n",
    "    # Rename kinds\n",
    "    kind_name = {1:\"generic\", 2:\"harmonic\", 3:\"automotive\"}\n",
    "    df[\"kind\"] = df[\"kind\"].apply(lambda x : kind_name[x])\n",
    "    \n",
    "    # Normalize listes \n",
    "    df.LowerBounds = df.apply(lambda x :  [y/x.AgeLatency for y in x.LowerBounds]  , axis = 1)\n",
    "    df.UpperBounds = df.apply(lambda x :  [y/x.AgeLatency for y in x.UpperBounds]  , axis = 1)\n",
    "    df.ExpansionVertex = df.apply(lambda x :  [y/(x.sum_n+2) for y in x.ExpansionVertex]  , axis = 1)\n",
    "\n",
    "    \n",
    "    ## Old test\n",
    "    #assert(df.ExpansionVertex.apply(max).max())\n",
    "    #assert(df.LowerBounds.apply(max).max())\n",
    "    #assert(df.UpperBounds.apply(max).max())\n",
    "\n",
    "    for label in [\"gen_time\", \"lbp_time\", \"ubp_time\"] :\n",
    "        df[label+\"_detail\"] = df[label].copy()\n",
    "        df[label] = df[label].apply(sum)\n",
    "                        \n",
    "                            \n",
    "    df[\"BoundsDistances\"] = df.apply(lambda x : [abs( l - r ) for (l,r) in zip(x.LowerBounds,x.UpperBounds)], axis=1)\n",
    "    df[\"bounds_shift\"] = df.apply ( lambda x : (x[\"LowerBounds\"].index(1) - x[\"UpperBounds\"].index(1)) if x[\"LowerBounds\"].count(1) else None , axis=1)\n",
    "    df[\"early_bounds\"] = df.apply ( lambda x : ((x[\"LowerBounds\"].index(1) + 1< len(x[\"LowerBounds\"])) and  (x[\"UpperBounds\"].index(1) + 1 < len(x[\"UpperBounds\"]) ))  if x[\"LowerBounds\"].count(1) else None , axis=1)\n",
    "    df['remain_time'] = (df[\"total_time\"] - df[\"gen_time\"] - df[\"lbp_time\"] - df[\"ubp_time\"])\n",
    "    \n",
    "\n",
    "    if len(with_gain) > 0 :\n",
    "        \n",
    "        df[\"ori_time\"] =  df[\"gen_time\"] + df[\"ubp_time\"]\n",
    "        df[\"ori_space\"] =  df.apply(lambda x : x.ExpansionVertex[x.IterationCount-1] , axis=1)\n",
    "\n",
    "        for delta in with_gain :\n",
    "            deltaStr  = str(delta)\n",
    "            target = 1.0 - (delta/100.0)\n",
    "\n",
    "            def when_to_finish (row) :\n",
    "                result = len(row.UpperBounds) - 1\n",
    "                for i in range(result):\n",
    "                    if (min(row.UpperBounds[:i+1]) - max(row.LowerBounds[:i+1])) <= (delta/100.0):\n",
    "                        return i\n",
    "                return result\n",
    "            df[\"NewIterationCount\"+deltaStr] = df.apply(when_to_finish, axis = 1) + 1\n",
    "            new_gen_time =  df.apply(lambda x: sum(x[\"gen_time_detail\"][:x[\"NewIterationCount\"+deltaStr]]), axis = 1)\n",
    "            new_lbp_time =  df.apply(lambda x: sum(x[\"lbp_time_detail\"][:x[\"NewIterationCount\"+deltaStr]]), axis = 1)\n",
    "            new_ubp_time =  df.apply(lambda x: sum(x[\"ubp_time_detail\"][:x[\"NewIterationCount\"+deltaStr]]), axis = 1)\n",
    "\n",
    "            new_time =   new_gen_time + new_lbp_time + new_ubp_time\n",
    "            \n",
    "            gain =  (df[\"ori_time\"] - new_time) / df[\"ori_time\"]\n",
    "            df[\"time_gain\"+deltaStr] = gain.fillna(0.0)\n",
    "            new_space = df.apply(lambda x : x.ExpansionVertex[x[\"NewIterationCount\"+deltaStr]-1] , axis=1)\n",
    "            gain =  (df[\"ori_space\"] - new_space) / df[\"ori_space\"]\n",
    "            df[\"space_gain\"+deltaStr] = gain.fillna(0.0)\n",
    "        \n",
    "        for label in [\"gen_time\", \"lbp_time\", \"ubp_time\"] :\n",
    "            df[label+\"_new\"] =  df.apply(lambda x: sum(x[label+\"_detail\"][:x[\"NewIterationCount0\"]]), axis = 1)\n",
    "\n",
    "        df[\"Iterations saved\"] = (df[\"IterationCount\"] - df[\"NewIterationCount0\"])\n",
    "        df[\"Iterations saved\"] = pd.Categorical(df[\"Iterations saved\"], ordered=True)\n",
    "    \n",
    "    \n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openLogs(filelist, **kwargs):\n",
    "    df = None\n",
    "    for f in filelist:\n",
    "        df = pd.concat([df,openLog(f, **kwargs)], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_df = openLogs([\"data/automotive.csv\", \"data/harmonic.csv\", \"data/generic.csv\"])\n",
    "data_full_df = openLogs([\"data/automotive.paper.csv\", \"data/harmonic.paper.csv\", \"data/generic.paper.csv\", \"data/automotive.csv\", \"data/automotivediti.csv\",\"data/harmonic.csv\",\"data/harmonicditi.csv\", \"data/containsAnomalies.csv\", \"data/generic.csv\", \"data/containsAnomalies_diti.csv\"])\n",
    "\n",
    "paper_df = openLogs([\"data/automotive.paper.csv\", \"data/harmonic.paper.csv\", \"data/generic.paper.csv\"])\n",
    "paper_df_withGain = openLogs([\"data/automotive.paper.csv\", \"data/harmonic.paper.csv\", \"data/generic.paper.csv\"], with_gain=np.arange(0,151,5))\n",
    "paper_df_withGain1 = openLogs([\"data/automotive.paper.csv\", \"data/harmonic.paper.csv\", \"data/generic.paper.csv\"], with_gain=np.arange(0,151,5))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  What is the maximum and minimum error we get from the first lower bound compared with the final latency ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_upper_detailled (df, alpha = None) :\n",
    "    if not alpha :\n",
    "        alpha = max ( 0.02,  1.0 / len(df) )\n",
    "    for (x,y) in list(df.apply(lambda x :  (x.ExpansionVertex, x.LowerBounds)  , axis = 1)) :\n",
    "        plt.plot(x,y, marker=\"o\", color = \"r\", alpha = alpha)\n",
    "    for (x,y) in list(df.apply(lambda x :  (x.ExpansionVertex, x.UpperBounds)  , axis = 1)) :\n",
    "        plt.plot(x,y, marker=\"o\", color = \"b\", alpha = alpha)\n",
    "    _ = plt.xlabel(\"Expansion Ratio to maximal\")\n",
    "    _ = plt.ylabel(\"Upper bound Ratio to optimal\")\n",
    "    _ = plt.title(\"Lower and Upper bounds progress over iterations\")\n",
    "df = data_base_df.copy()    \n",
    "lower_upper_detailled (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Set the font size\n",
    "#sns.set_context(\"notebook\", font_scale=1.5)  # Adjust font_scale as needed\n",
    "\n",
    "def summarizePlots(df) :\n",
    "    with sns.axes_style('white'):\n",
    "        #_ = sns.jointplot(\"n\", \"m\", data=df, kind='hex')\n",
    "        _ = sns.pairplot(data=df[[ \"n\",\"m\",  \"sum_n\", \"IterationCount\"]], hue=\"n\")\n",
    "summarizePlots(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study of the bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBoundsByIteration(df, itercount) :\n",
    "    sdf  =  df[df.IterationCount == itercount]\n",
    "    _ = plt.violinplot(pd.DataFrame(sdf.LowerBounds.to_list(), columns=range(itercount)))\n",
    "    _ = plt.violinplot(pd.DataFrame(sdf.UpperBounds.to_list(), columns=range(itercount)))\n",
    "    _ = plt.xlabel(\"Iteration\")\n",
    "    _ = plt.ylabel(\"Lower/Upper bounds ratio to optimal\")\n",
    "    \n",
    "plotBoundsByIteration(df, 5)\n",
    "_ = plt.title(\"Lower and Upper bounds progress over iterations for 5-iterations cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(1,df.IterationCount.max() + 1) :\n",
    "    if len(df[df.IterationCount == it]) > 1:\n",
    "        plotBoundsByIteration(df, it)\n",
    "_ = plt.title(\"Lower and Upper bounds progress over iterations for all cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBounds(df, title = None) :\n",
    "    sdf = df.copy()\n",
    "    sdf.LowerBounds = sdf.LowerBounds.apply(lambda x: [max(x[:i]+[x[i]]) for i in range(len(x))])\n",
    "    sdf.LowerBounds = sdf.apply (lambda x : x.LowerBounds + (df.IterationCount.max() - x.IterationCount)*x.LowerBounds[-1:], axis = 1)\n",
    "    sdf.UpperBounds = sdf.apply (lambda x : x.UpperBounds + (df.IterationCount.max() - x.IterationCount)*x.UpperBounds[-1:], axis = 1)\n",
    "    plt.figure()\n",
    "    _ = plt.violinplot(pd.DataFrame(sdf.LowerBounds.to_list(), columns=range(df.IterationCount.max())))\n",
    "    _ = plt.violinplot(pd.DataFrame(sdf.UpperBounds.to_list(), columns=range(df.IterationCount.max())))\n",
    "    _ = plt.xlabel(\"Iteration\")\n",
    "    _ = plt.ylabel(\"Lower/Upper bounds ratio to optimal\")\n",
    "    if title is None :\n",
    "        _ = plt.title(\"Lower and Upper bounds progress over iterations for all cases\")\n",
    "    else :\n",
    "        _ = plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBounds(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBoundsDistances(df) :\n",
    "    sdf = df.copy()\n",
    "    sdf.BoundsDistances = sdf.apply (lambda x : x.BoundsDistances + (sdf.IterationCount.max() - x.IterationCount)*x.BoundsDistances[-1:], axis = 1)\n",
    "    _ = plt.violinplot(pd.DataFrame(sdf.BoundsDistances.to_list(), columns=range(sdf.IterationCount.max())))\n",
    "    _ = plt.title(\"Bounds distance for every iterations\")\n",
    "    _ = plt.xlabel(\"Iteration\")\n",
    "    _ = plt.ylabel(\"Bounds distance ratio to optimal\")\n",
    "plotBoundsDistances(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMinMaxBoundDistance (df, label1 = \"Minimal distance\", label2 = \"Maximal distance\") :\n",
    "    sdf = df.copy()\n",
    "    sdf.BoundsDistances = sdf.apply (lambda x : x.BoundsDistances + (sdf.IterationCount.max() - x.IterationCount)*x.BoundsDistances[-1:], axis = 1)\n",
    "    sdf[\"BoundsDistancesMax\"] = sdf.BoundsDistances.apply(lambda x : max(x))\n",
    "\n",
    "    x = sdf.groupby(\"n\").max().reset_index()[\"n\"]\n",
    "    y1 = sdf.groupby(\"n\").min().reset_index()[\"BoundsDistancesMax\"]\n",
    "    y2 = sdf.groupby(\"n\").max().reset_index()[\"BoundsDistancesMax\"]\n",
    "\n",
    "    _ = plt.plot(x,y1,  label = label1)\n",
    "    _ = plt.plot(x,y2,  label = label2)\n",
    "    _ = plt.title(\"Min and Maximum distance between bounds per graph size\")\n",
    "    _ = plt.xlabel(\"Graph size (N)\")\n",
    "    _ = plt.ylabel(\"Distance between bounds\")\n",
    "    _ = plt.legend()\n",
    "plotMinMaxBoundDistance(df[df.IterationCount > 5], label1=\"Min Distance (iter > 5)\", label2=\"Max Distance (iter > 5)\")\n",
    "plotMinMaxBoundDistance(df[df.IterationCount <= 5], label1=\"Min Distance (iter <= 5)\", label2=\"Max Distance (iter <= 5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "    \n",
    "def plotDataFrame(_df, header=\"Untitled\") :\n",
    "    fig, axes = plt.subplots(3,2,figsize=(10,10))\n",
    "    fig.suptitle(f'Summary from {header}')\n",
    "    plt.sca(axes[0,0])\n",
    "    plotBounds(_df)\n",
    "    plt.sca(axes[1,0])\n",
    "    plotBoundsDistances(_df)\n",
    "    plt.sca(axes[0,1])\n",
    "    lower_upper_detailled(_df)\n",
    "    plt.sca(axes[1,1])\n",
    "    plotMinMaxBoundDistance(_df)\n",
    "    plt.sca(axes[2,0])\n",
    "    df[\"bounds_shift\"].hist()\n",
    "    plt.tight_layout()\n",
    "    summarizePlots(_df)\n",
    "    _ = df[[ \"n\",\"m\",  \"sum_n\", \"IterationCount\"]].hist()\n",
    "    \n",
    "def plotDataFile(filename) :\n",
    "    _df = openLog(filename)\n",
    "    plotDataFrame(_df, filename)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDataFile(\"data/generic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDataFile(\"data/automotivediti.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir figures -p\n",
    "!rm -f figures/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Instance :\n",
    "    def __init__ (self, n,m,seed,kind, DiEqTi) :\n",
    "        self.n   = n\n",
    "        self.m   = m\n",
    "        self.kind   = kind\n",
    "        self.seed   = seed\n",
    "        self.DiEqTi = DiEqTi\n",
    "        \n",
    "    def __str__ (self) :\n",
    "        return f\"Instance ({self.n}, {self.m}, {self.seed}, {self.kind}, {self.DiEqTi})\"\n",
    "    def __repr__ (self) :\n",
    "        return self.__str__()\n",
    "\n",
    "def getLET(inst): \n",
    "    import os \n",
    "    import subprocess\n",
    "    import sys\n",
    "    from IPython import display\n",
    "    valid_kinds = ALL_KIND\n",
    "    n  = inst.n\n",
    "    m = inst.m\n",
    "    seed = inst.seed\n",
    "    kind = inst.kind\n",
    "    DiEqTi = inst.DiEqTi\n",
    "    \n",
    "    if kind == 1 : kind = \"generic\"\n",
    "    if not kind in valid_kinds :\n",
    "        print (f\"invalid kind '{kind}'\")\n",
    "    assert( kind in valid_kinds )\n",
    "        \n",
    "    cmd = [ANALYSE, \"-n\", str(n), \"-m\", str(m), \"-seed\", str(seed), \"-kind\", kind, \"-outputsvg\"]\n",
    "    if DiEqTi :\n",
    "        cmd .append(\"-DiEqualTi\")\n",
    "    sys.stderr.write(f\" \" + \" \".join(cmd))\n",
    "    \n",
    "    proc = subprocess.Popen([str(x) for x in cmd], stdout=subprocess.PIPE)\n",
    "    out,err = proc.communicate()\n",
    "    return display.SVG(out)\n",
    "\n",
    "def getPEG(inst, upper=None, lower=None): \n",
    "    import os \n",
    "    import subprocess\n",
    "    import sys\n",
    "    from IPython import display\n",
    "    assert (upper == None or lower==None) # Need only on of them\n",
    "    \n",
    "    n  = inst.n\n",
    "    m = inst.m\n",
    "    seed = inst.seed\n",
    "    kind = inst.kind\n",
    "    DiEqTi = inst.DiEqTi\n",
    "    \n",
    "    if kind == 1 : kind = \"generic\"\n",
    "        \n",
    "    if (upper) : peg_k = \" \".join([str(x) for x in upper])    \n",
    "    if (lower) : peg_k = \" \".join([str(x) for x in lower])   \n",
    "        \n",
    "    cmd = [ANALYSE, \"-n\", str(n), \"-m\", str(m), \"-seed\", str(seed), \"-kind\", kind, \n",
    "           \"-outputsvg\", \"-peg\", peg_k]\n",
    "    if DiEqTi :\n",
    "        cmd .append(\"-DiEqualTi\")\n",
    "    sys.stderr.write(f\" \" + \" \".join(cmd))\n",
    "    proc = subprocess.Popen([str(x) for x in cmd], stdout=subprocess.PIPE)\n",
    "    out,err = proc.communicate()\n",
    "    required = \"\"\n",
    "    res = \"\"\n",
    "    current = \"\"\n",
    "    if upper :\n",
    "        required = f\"// Upper bound\"\n",
    "    if lower :\n",
    "        required = f\"// Lower bound\"\n",
    "    print (f\"<!-- {required} -->\")\n",
    "    for line in out.decode(\"utf-8\").split(\"\\n\"):\n",
    "        if line[:2] == \"//\" or line[:1] == \"%\":\n",
    "            current = line\n",
    "            if required == \"\" :\n",
    "                print (line)\n",
    "        elif current.startswith(required) :\n",
    "            res += (line)\n",
    "    return display.SVG(res)\n",
    "\n",
    "def saveSVGIntoPNG(obj, filename):\n",
    "    from cairosvg import svg2png\n",
    "    svg2png(bytestring=obj.data,write_to=filename)\n",
    "        \n",
    "def saveInto(obj, filename):\n",
    "    with open(filename, 'w') as fdesc:\n",
    "        fdesc.write(obj)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def execute_and_process(df, cmd_template, process):\n",
    "    \"\"\"\n",
    "    Executes a command for each row in the dataframe and processes the output.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing columns 'n', 'm', and 'seed'.\n",
    "        cmd_template (str): Command template with placeholders for arguments, e.g., \"cmd -n {n} -m {m} -seed {seed}\".\n",
    "        process (function): A function that takes the output of the command and processes it.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of processed results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # Prepare the command by substituting arguments\n",
    "        cmd = cmd_template.format(n=row['n'], m=row['m'], seed=row['seed'])\n",
    "\n",
    "        try:\n",
    "            # Run the command and capture the output\n",
    "            result = subprocess.run(\n",
    "                cmd, shell=True, capture_output=True, text=True, check=True\n",
    "            )\n",
    "            \n",
    "            # Process the command output\n",
    "            processed_result = process(row, result.stdout)\n",
    "            results.append(processed_result)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error executing command: {cmd}\\n{e.stderr}\")\n",
    "            results.append(None)  # Append None if the command fails\n",
    "\n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking for a sample\n",
    "\n",
    "I'm looking for a sample that showcases pimin/pimax, and lower/upper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = data_full_df.copy()\n",
    "\n",
    "# small instances but with interesting properties\n",
    "samples_df = samples_df[samples_df[\"sum_n\"] > 100]\n",
    "samples_df = samples_df[samples_df[\"n\"] == 4]\n",
    "samples_df = samples_df[samples_df[\"m\"] == 3]\n",
    "samples_df = samples_df[samples_df[\"IterationCount\"] == 3]\n",
    "\n",
    "# Lower bound find it first.\n",
    "samples_df = samples_df[samples_df.apply(lambda x : x.LowerBounds.count(1.0) != 0,axis=1)]\n",
    "#samples_df = samples_df[samples_df.apply(lambda x : x.LowerBounds.index(1.0) < x.UpperBounds.index(1.0),axis=1)]\n",
    "samples_df = samples_df[samples_df.apply(lambda x: all(x.LowerBounds[i] < x.LowerBounds[i+1] for i in range(len(x.LowerBounds) - 1)), axis=1)]\n",
    "\n",
    "# Output instances\n",
    "print(samples_df.columns)\n",
    "samples_df[[\"seed\",\"kind\",\"n\", \"m\", \"DiEqTi\",\"sum_n\", \"LowerBounds\", \"UpperBounds\", \"filename\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_process(row, output):\n",
    "    if \"len(UP): 3\" in output.strip() :\n",
    "        return row\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Command template\n",
    "command_template = ANALYSE + \" -kind generic  -agelatency -n {n} -m {m} -seed {seed}\"\n",
    "\n",
    "# Execute and process\n",
    "results = execute_and_process(samples_df, command_template, sample_process)\n",
    "for l in results:\n",
    "    if l is not None :\n",
    "        print(l[\"n\"],l[\"m\"],l[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATION_PARAMETERS=ANALYSE + \" -n 4 -m 3 -seed 818 -kind generic \" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures and Tables for the example\n",
    "\n",
    "## Figure 2\n",
    "\n",
    "DAG and r,D,T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script env CMD=\"$GENERATION_PARAMETERS\" bash\n",
    "$CMD  -outputtikzdag -outputtabularLET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3\n",
    "\n",
    "Schedule view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script env CMD=\"$GENERATION_PARAMETERS\" bash\n",
    "$CMD   -outputtikzschedule -schedule_duration 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4\n",
    "\n",
    "Alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script env CMD=\"$GENERATION_PARAMETERS\" bash\n",
    "$CMD   -outputalphas 1 -agelatency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5\n",
    "\n",
    "PEG of the first iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script env CMD=\"$GENERATION_PARAMETERS\" bash\n",
    "$CMD   -outputtikzPEG  -agelatency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1\n",
    "\n",
    "List of iterations for Kiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script env CMD=\"$GENERATION_PARAMETERS\" bash\n",
    "$CMD      -outputtabularAlgo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use-cases\n",
    "\n",
    "## Use-case 1: When Lower bound reach optimality first\n",
    "\n",
    "This example shows a situation where lower bound can help to interupt computation earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = data_full_df.copy()\n",
    "\n",
    "# small instances but with interesting properties\n",
    "#samples_df = samples_df[samples_df[\"sum_n\"] > 100]\n",
    "#samples_df = samples_df[samples_df[\"n\"] == 4]\n",
    "#samples_df = samples_df[samples_df[\"m\"] == 3]\n",
    "#samples_df = samples_df[samples_df[\"IterationCount\"] == 3]\n",
    "\n",
    "# Lower bound find it first.\n",
    "samples_df = samples_df[samples_df.apply(lambda x : x.LowerBounds.count(1.0) == 1,axis=1)]\n",
    "samples_df = samples_df[samples_df.apply(lambda x : x.LowerBounds.index(1.0) < x.UpperBounds.index(1.0),axis=1)]\n",
    "#samples_df = samples_df[samples_df.apply(lambda x: all(x.LowerBounds[i] < x.LowerBounds[i+1] for i in range(len(x.LowerBounds) - 1)), axis=1)]\n",
    "\n",
    "# Output instances\n",
    "print(samples_df.columns)\n",
    "samples_df[[\"seed\",\"kind\",\"n\", \"m\", \"DiEqTi\",\"sum_n\", \"LowerBounds\", \"UpperBounds\", \"filename\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script env ANALYSE=\"$ANALYSE\" bash\n",
    "$ANALYSE -n 4 -m 4 -seed 3783 -kind generic  -agelatency  -outputtikzschedule -schedule_duration 30 -outputtabularAlgo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use-case 2: When lower bound does not reach optimality\n",
    "\n",
    "It is very interesting to note the existence of instances where, considering Algoritm 1, the lower bound will not be able to reach optimality. \n",
    "These very rare cases are possible, and force us to verify the original condition from Ning in addition of comparing lower and upper bound. \n",
    "\n",
    "The following example is one of these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = data_full_df.copy()\n",
    "\n",
    "# small instances but with interesting properties\n",
    "samples_df = samples_df[samples_df[\"sum_n\"] > 100]\n",
    "samples_df = samples_df[samples_df[\"n\"] == 4]\n",
    "samples_df = samples_df[samples_df[\"m\"] == 3]\n",
    "samples_df = samples_df[samples_df[\"IterationCount\"] == 3]\n",
    "\n",
    "# Lower bound find it first.\n",
    "samples_df = samples_df[samples_df.apply(lambda x : x.LowerBounds.count(1.0) == 0,axis=1)]\n",
    "#samples_df = samples_df[samples_df.apply(lambda x : x.LowerBounds.index(1.0) < x.UpperBounds.index(1.0),axis=1)]\n",
    "\n",
    "# Output instances\n",
    "print(samples_df.columns)\n",
    "samples_df[[\"seed\",\"kind\",\"n\", \"m\", \"DiEqTi\",\"sum_n\", \"LowerBounds\", \"UpperBounds\", \"filename\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script env ANALYSE=\"$ANALYSE\" bash\n",
    "$ANALYSE -n 4 -m 3 -DiEqualTi -seed 7929 -kind generic -agelatency  -outputtikzschedule -schedule_duration 30 -outputtabularAlgo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-case 3: When lower bound decrease while K increase. \n",
    "\n",
    "Since Bodin2016, it is accepted that increasing the values of K arbitrarily does not necessarily improve estiation results.\n",
    "However a dominant subset has been identified and consistantly improve the upper bound. \n",
    "Meanwhile we found example where an update of K can degrade the lower bound despite improving the upper bound.\n",
    "\n",
    "In this example, the upper bound ciritical path for K=1,1,1,1 indicate a new vector K=[8,3,24,1,3]. This new vector K reach optimality.\n",
    "However, the same update of K for the lower bound has the oposite effect that while lower bound was 19 initially, it went down to 12 after this update of K.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = data_full_df.copy()\n",
    "filtered_df = filtered_df[filtered_df[\"IterationCount\"] >=  3]\n",
    "filtered_df = filtered_df[filtered_df[\"sum_n\"] < 60]\n",
    "filtered_df = filtered_df[filtered_df[\"n\"] >= 4]\n",
    "filtered_df = filtered_df[filtered_df[\"m\"] >= 4]\n",
    "filtered_df = filtered_df[filtered_df.apply(lambda x : x.LowerBounds[1] > x.LowerBounds[2],axis=1)]\n",
    "\n",
    "filtered_df[[\"seed\",\"n\", \"m\", \"sum_n\", \"LowerBounds\", \"UpperBounds\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures for experiments \n",
    "\n",
    "## Generate DataSet analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script env BENCHMARK=\"$BENCHMARK\" bash\n",
    "\n",
    "for kind in automotive harmonic generic ; do \n",
    "    if [ ! -e data/$kind.dataset.csv ]; then \n",
    "        $BENCHMARK -kind $kind -begin_n 1 -end_n 500  -step_n 1 -sample_count 1 -iter_count 3 -dryrun -detailed -logfile data/$kind.dataset.csv;\n",
    "    fi\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = openLogs([\"data/automotive.dataset.csv\", \"data/harmonic.dataset.csv\", \"data/generic.dataset.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = dataset_df[[\"kind\",\"edge_density\", \"n\", \"m\", \"sum_n\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure only numeric columns are included\n",
    "numeric_columns = dataset_df.select_dtypes(include='number')\n",
    "\n",
    "# Group and compute the mean\n",
    "result = numeric_columns.groupby([dataset_df[\"n\"], dataset_df[\"kind\"]]).mean().transpose()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot(x=\"n\", y=\"m\", hue=\"edge_density\", data=dataset_df, legend=False, height=4, aspect= 2, order=3)\n",
    "_ = g.ax.legend(loc=2)\n",
    "\n",
    "# Manually set specific font sizes (optional)\n",
    "#g.ax.set_title(\"\", fontsize=16)\n",
    "g.ax.set_xlabel(\"Task count\", fontsize=16)\n",
    "g.ax.set_ylabel(\"Edge count\", fontsize=16)\n",
    "g.ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "g.ax.legend(fontsize=16, title_fontsize=16)  # Legend font sizes\n",
    "\n",
    "plt.savefig(\"figures/dataset_size.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot(x=\"n\", y=\"sum_n\", hue=\"kind\", data=dataset_df, legend=False, height=4, aspect= 2)\n",
    "g = g.set_axis_labels(\"Task count\", \"Expansion size\")\n",
    "_ = g.ax.legend(loc=2)\n",
    "\n",
    "#g.ax.set_title(\"\", fontsize=16)\n",
    "g.ax.set_xlabel(\"Task count\", fontsize=16)\n",
    "g.ax.set_ylabel(\"Expansion size\", fontsize=16)\n",
    "g.ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "g.ax.legend(fontsize=16, title_fontsize=16)  # Legend font sizes\n",
    "\n",
    "\n",
    "plt.savefig(\"figures/dataset_complexity.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating timing analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure only numeric columns are included\n",
    "numeric_columns = df.select_dtypes(include='number')\n",
    "\n",
    "# Group and compute the mean\n",
    "result = numeric_columns.groupby([dataset_df[\"n\"], dataset_df[\"kind\"]]).mean().transpose()\n",
    "\n",
    "\n",
    "for kind in ALL_KIND:\n",
    "    df = paper_df_withGain1[paper_df_withGain1[\"kind\"] == kind].copy() \n",
    "\n",
    "    # Ensure 'n' is numeric for pd.cut\n",
    "    df['n'] = pd.to_numeric(df['n'], errors='coerce')\n",
    "\n",
    "    # Create 'NRange' column\n",
    "    df['NRange'] = pd.cut(df['n'], range(0, 501, 50))\n",
    "\n",
    "    # Compute mean for numeric columns grouped by 'NRange'\n",
    "    df_mean = df.select_dtypes(include='number').groupby(df[\"NRange\"]).mean()\n",
    "    # Define consistent colors for bars\n",
    "    bar_colors = {\n",
    "        \"gen_time_new\": \"tab:blue\",\n",
    "        \"lbp_time_new\": \"tab:orange\",\n",
    "        \"ubp_time_new\": \"tab:green\",\n",
    "        \"gen_time\": \"tab:blue\",\n",
    "        \"lbp_time\": \"tab:orange\",\n",
    "        \"ubp_time\": \"tab:green\"\n",
    "    }\n",
    "    # Create subplots for new and old timings\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6), sharex=False, sharey=True)\n",
    "\n",
    "    # Plot new timings\n",
    "    df_mean.plot(\n",
    "        kind='bar',\n",
    "        y=[\"gen_time_new\", \"lbp_time_new\", \"ubp_time_new\"],\n",
    "        stacked=True,\n",
    "        ax=axes[0],\n",
    "        color=[bar_colors[col] for col in [\"gen_time_new\", \"lbp_time_new\", \"ubp_time_new\"]],\n",
    "        legend=False\n",
    "    )\n",
    "    axes[0].set_title(f\"Using the lower bound - {kind}\", fontsize=14)\n",
    "    axes[0].set_ylabel(\"Time (seconds)\", fontsize=12)\n",
    "    axes[0].set_xlabel(\"Graph Size\", fontsize=12)\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Plot old timings\n",
    "    df_mean.plot(\n",
    "        kind='bar',\n",
    "        y=[\"gen_time\", \"ubp_time\"],\n",
    "        stacked=True,\n",
    "        ax=axes[1],\n",
    "        color=[bar_colors[col] for col in [\"gen_time\", \"ubp_time\"]],\n",
    "        legend=False\n",
    "    )\n",
    "    axes[1].set_title(f\"Without using the lower bound - {kind}\", fontsize=14)\n",
    "    axes[1].set_ylabel(\"\")  # Remove redundant Y-axis label\n",
    "    axes[1].set_xlabel(\"Graph Size\", fontsize=12)\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Add a single legend for the entire figure\n",
    "    fig.legend(\n",
    "        [\"Graph Generation Time\", \"Lower Bound Processing\", \"Upper Bound Processing\"],\n",
    "        loc=\"upper center\",\n",
    "        ncol=3,\n",
    "        fontsize=12\n",
    "    )\n",
    "\n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.92])  # Leave space for the legend\n",
    "    plt.savefig(f\"figures/comparison_timings_{kind}.pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Improvement analysis\n",
    "\n",
    "### Execution time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is so brutal, I should find how to do this properly !!! \n",
    "df = paper_df_withGain.copy()\n",
    "tmp = df.groupby([\"kind\",\"edge_density\",\"n\"]).min()[[x for x in df.columns if \"time_gain\" in x]].reset_index()\n",
    "\n",
    "res = None\n",
    "for gainVal in np.arange(0,151,5) :\n",
    "    start = tmp[[\"kind\",\"edge_density\",\"n\"]].copy()\n",
    "    start[\"Accepted error\"] = gainVal\n",
    "    start[\"Computational gain\"] = tmp[\"time_gain\" + str(gainVal)] * 100\n",
    "    start\n",
    "    res = pd.concat([res,start], ignore_index=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the relplot without the default legend\n",
    "\n",
    "# Create the line plot\n",
    "fig, ax = plt.subplots(figsize=(8, 4))  # Adjust the figure size (aspect ratio = 2)\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"Accepted error\",\n",
    "    y=\"Computational gain\",\n",
    "    hue=\"kind\",\n",
    "    data=res,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Move the legend inside the plot\n",
    "sns.move_legend(ax, \"lower right\", bbox_to_anchor=(1, 0))\n",
    "\n",
    "\n",
    "# Manually set specific font sizes (optional)\n",
    "ax.set_title(\"Computational Gain vs Accepted Error\", fontsize=16)\n",
    "ax.set_xlabel(\"Accepted Error\", fontsize=16)\n",
    "ax.set_ylabel(\"Computational Gain\", fontsize=16)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.legend(fontsize=16, title_fontsize=16)  # Legend font sizes\n",
    "\n",
    "plt.savefig(\"figures/computational_gain.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the time spent on the first iteration over N compared to the time spent on the total?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame\n",
    "df = paper_df_withGain.copy()\n",
    "\n",
    "# Ensure numeric columns for space gain\n",
    "space_gain_cols = [col for col in df.columns if \"space_gain\" in col]\n",
    "\n",
    "# Group by \"kind\" and \"edge_density\", and calculate the mean for space gain columns\n",
    "tmp = df.groupby([\"kind\", \"edge_density\"])[space_gain_cols].mean().reset_index()\n",
    "\n",
    "# Initialize the result DataFrame\n",
    "res = []\n",
    "\n",
    "# Iterate over gain values and construct the result DataFrame\n",
    "for gainVal in np.arange(0, 151, 5):\n",
    "    temp = tmp[[\"kind\", \"edge_density\"]].copy()  # Preserve 'kind' and 'edge_density'\n",
    "    temp[\"Accepted error\"] = gainVal\n",
    "    temp[\"Spacial gain\"] = tmp[f\"space_gain{gainVal}\"] * 100  # Dynamically select the column\n",
    "    res.append(temp)\n",
    "\n",
    "# Concatenate all the intermediate results\n",
    "res = pd.concat(res, ignore_index=True)\n",
    "\n",
    "# Display or process `res` further\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the line plot\n",
    "fig, ax = plt.subplots(figsize=(8, 4))  # Adjust the figure size (aspect ratio = 2)\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"Accepted error\",\n",
    "    y=\"Spacial gain\",\n",
    "    hue=\"kind\",\n",
    "    data=res,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Move the legend inside the plot\n",
    "sns.move_legend(ax, \"lower right\", bbox_to_anchor=(1, 0))\n",
    "\n",
    "\n",
    "# Manually set specific font sizes (optional)\n",
    "ax.set_title(\"Spacial Gain vs Accepted Error\", fontsize=16)\n",
    "ax.set_xlabel(\"Accepted Error\", fontsize=16)\n",
    "ax.set_ylabel(\"Spacial Gain\", fontsize=16)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.legend(fontsize=16, title_fontsize=16)  # Legend font sizes\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(\"figures/spacial_gain.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the line plot\n",
    "fig, ax = plt.subplots(figsize=(8, 4))  # Adjust the figure size (aspect ratio = 2)\n",
    "\n",
    "sns.lineplot(\n",
    "    x=\"Accepted error\",\n",
    "    y=\"Spacial gain\",\n",
    "    hue=\"kind\",\n",
    "    data=res,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Move the legend inside the plot\n",
    "sns.move_legend(ax, \"lower right\", bbox_to_anchor=(1, 0))\n",
    "\n",
    "\n",
    "# Manually set specific font sizes (optional)\n",
    "ax.set_title(\"Spacial Gain vs Accepted Error\", fontsize=16)\n",
    "ax.set_xlabel(\"Accepted Error\", fontsize=16)\n",
    "ax.set_ylabel(\"Spacial Gain\", fontsize=16)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.legend(fontsize=16, title_fontsize=16)  # Legend font sizes\n",
    "\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bound analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def plotBounds(df, title=None):\n",
    "    sdf = df.copy()\n",
    "    sdf.LowerBounds = sdf.LowerBounds.apply(lambda x: [max(x[:i] + [x[i]]) for i in range(len(x))])\n",
    "    sdf.LowerBounds = sdf.apply(\n",
    "        lambda x: x.LowerBounds + (df.IterationCount.max() - x.IterationCount) * x.LowerBounds[-1:], axis=1\n",
    "    )\n",
    "    sdf.UpperBounds = sdf.apply(\n",
    "        lambda x: x.UpperBounds + (df.IterationCount.max() - x.IterationCount) * x.UpperBounds[-1:], axis=1\n",
    "    )\n",
    "    plt.figure(figsize=(10, 6))  # Set figure size\n",
    "    _ = plt.violinplot(pd.DataFrame(sdf.LowerBounds.to_list(), columns=range(df.IterationCount.max())))\n",
    "    _ = plt.violinplot(pd.DataFrame(sdf.UpperBounds.to_list(), columns=range(df.IterationCount.max())))\n",
    "    _ = plt.xlabel(\"Iteration\", fontsize=14)  # Larger font size for x-axis label\n",
    "    _ = plt.ylabel(\"Lower/Upper bounds ratio to optimal\", fontsize=16)  # Larger font size for y-axis label\n",
    "    if title is None:\n",
    "        _ = plt.title(\"Lower and Upper bounds progress over iterations for all cases\", fontsize=16)  # Larger title font\n",
    "    else:\n",
    "        _ = plt.title(title, fontsize=16)  # Larger title font\n",
    "    plt.xticks(fontsize=16)  # Increase font size of x-ticks\n",
    "    plt.yticks(fontsize=16)  # Increase font size of y-ticks\n",
    "    plt.tight_layout()  # Adjust layout to fit everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = paper_df.copy()\n",
    "for kind in ALL_KIND:\n",
    "    plotBounds(df[df[\"kind\"] == kind], title = f\"Lower and Upper bounds for {kind}\") \n",
    "    plt.savefig(f\"figures/bounds_{kind}.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration Count \n",
    "\n",
    "Edge density has no impact on edge density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = paper_df.copy()\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 5))  # Adjust the figure size (aspect=2)\n",
    "\n",
    "# Plot using histplot\n",
    "sns.histplot(\n",
    "    data=df,\n",
    "    x=\"IterationCount\",\n",
    "    hue=\"kind\",\n",
    "    multiple=\"dodge\",\n",
    "    ax=ax,\n",
    "    legend=True  # Keep legend enabled\n",
    ")\n",
    "\n",
    "# Customize labels and title\n",
    "ax.set_title(\"Distribution of Iteration Count by Kind\", fontsize=16)\n",
    "ax.set_xlabel(\"Iteration Count\", fontsize=16)\n",
    "ax.set_ylabel(\"Frequency\", fontsize=16)\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=16)\n",
    "    \n",
    "plt.setp(ax.get_legend().get_texts(), fontsize=16) # for legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize=16) # for legend title\n",
    "\n",
    "plt.savefig(f\"figures/iterations_distribution_by_kind.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = paper_df.copy()\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 5))  # Adjust the figure size (aspect=2)\n",
    "\n",
    "# Plot using histplot\n",
    "sns.histplot(\n",
    "    data=df,\n",
    "    x=\"IterationCount\",\n",
    "    hue=\"edge_density\",\n",
    "    multiple=\"dodge\",\n",
    "    ax=ax,\n",
    "    legend=True  # Keep legend enabled\n",
    ")\n",
    "\n",
    "# Customize labels and title\n",
    "ax.set_title(\"Distribution of Iteration Count by Kind\", fontsize=16)\n",
    "ax.set_xlabel(\"Iteration Count\", fontsize=16)\n",
    "ax.set_ylabel(\"Frequency\", fontsize=16)\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=16)\n",
    "    \n",
    "plt.setp(ax.get_legend().get_texts(), fontsize=16) # for legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize=16) # for legend title\n",
    "\n",
    "plt.savefig(f\"figures/iterations_distribution_by_density.pdf\", bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterations saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = paper_df_withGain.copy()\n",
    "\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 5))  # Adjust the figure size\n",
    "\n",
    "# Plot using histplot\n",
    "sns.histplot(\n",
    "    x=\"Iterations saved\",\n",
    "    data=df,\n",
    "    log_scale=False,  # No log scale applied\n",
    "    kde=False,  # Disable KDE\n",
    "    shrink=0.8,  # Shrink the bars\n",
    "    hue=\"kind\",  # Group by 'kind'\n",
    "    multiple=\"dodge\",  # Dodge overlapping bars\n",
    "    ax=ax  # Use the defined axis\n",
    ")\n",
    "\n",
    "\n",
    "# Customize labels and title\n",
    "ax.set_title(\"Iterations Saved by Kind\", fontsize=16)\n",
    "ax.set_xlabel(\"Iterations Saved\", fontsize=16)\n",
    "ax.set_ylabel(\"Frequency\", fontsize=16)\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=16)\n",
    "# Adjust legend font size\n",
    "\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize=16) # for legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize=16) # for legend title\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(f\"figures/saved_iterations.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
